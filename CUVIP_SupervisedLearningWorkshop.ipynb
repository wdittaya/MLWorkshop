{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wdittaya/MLWorkshop/blob/main/CUVIP_SupervisedLearningWorkshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWDH6rVEwTdM"
      },
      "source": [
        "# Dataset\n",
        "This dataset contains voltage, current, power, energy, and weather data from low-voltage substations and domestic premises with high uptake of solar photovoltaic (PV) embedded generation.\n",
        "\n",
        "Key stats about the dataset:\n",
        "\n",
        "- 20 substations and 10 domestic premises\n",
        "- Collected over 480 days - 27 July 2013 to 19 November 2014\n",
        "- 10 minute intervals over all time recorded, 1 minute intervals in summer 2014\n",
        "- 10-minute measurements prior to 10 June 2014, aggregated to hourly minima and maxima\n",
        "\n",
        "Ref: https://data.london.gov.uk/dataset/photovoltaic--pv--solar-panel-energy-generation-data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# โจทย์\n",
        "\n",
        "1. ทำนายกำลังการผลิตไฟฟ้าใน 1 ชั่วโมงข้างหน้าจากข้อมูลสภาวะอากาศย้อนหลัง 3 ชั่วโมง\n",
        "2. ทำนายปริมาณการซื้อไฟฟ้าล่วงหน้า 1 ชั่วโมง จากข้อมูลการใช้ไฟฟ้าและการผลิตไฟฟ้าย้อนหลัง 3 ชั่วโมง"
      ],
      "metadata": {
        "id": "GjwzymdCKAHG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download ข้อมูล"
      ],
      "metadata": {
        "id": "GD6a1fPHKdY2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ข้อมูลการผลิตไฟฟ้า"
      ],
      "metadata": {
        "id": "CqHXnZi-LF0y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yD32trYJwL8L"
      },
      "outputs": [],
      "source": [
        "!wget https://data.london.gov.uk/download/photovoltaic--pv--solar-panel-energy-generation-data/81fb6b31-f6b2-4e12-b054-090319faec7b/PV%20Data.zip\n",
        "!unzip 'PV Data.zip'\n",
        "!unzip 'PV Data - csv files only.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ข้อมูลสภาพอากาศ"
      ],
      "metadata": {
        "id": "iX3aihULLKC-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GtQwmvzwjoP"
      },
      "outputs": [],
      "source": [
        "!wget https://data.london.gov.uk/download/photovoltaic--pv--solar-panel-energy-generation-data/b4a7e790-8cb8-451c-b828-c4c5d8445705/Weather%20Data%202014-11-30.xlsx"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "เลือกใช้ข้อมูลการผลิตไฟฟ้าจากบ้านลูกค้า (customer endpoint) ราย 10 นาที"
      ],
      "metadata": {
        "id": "hCbLH6xML5Go"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bV_XO912wo1D"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "customer_data_df = pd.read_csv('/content/2014-11-28 Cleansed and Processed/EXPORT TenMinData/EXPORT TenMinData - Customer Endpoints.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHTCvz1OzvWd"
      },
      "outputs": [],
      "source": [
        "customer_data_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(customer_data_df.iloc[0])"
      ],
      "metadata": {
        "id": "htrItgx3P4K4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fields ที่จะใช้\n",
        "- `Substation` สถานีย่อย\n",
        "- `d_y` ปี\n",
        "- `d_m` เดือน\n",
        "- `d_d` วันที่\n",
        "- `d_w` วันของสัปดาห์\n",
        "- `t_h` ชั่วโมง\n",
        "- `t_m` นาที\n",
        "- `P_GEN` ปริมาณที่ผลิตเพื่อใช้ (kWatt)\n",
        "- `P_IMPORT` ปริมาณไฟฟ้าที่ต้องซื้อ (kWatt)\n",
        "    - ค่าเป็นบวกกรณีซื้อไฟฟ้า (ผลิตไม่พอใช้)\n",
        "    - ค่าเป็นลบกรณีขายไฟฟ้า (ผลิตเกินที่ใช้)"
      ],
      "metadata": {
        "id": "XpqyotmzO226"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URpSuKAs0BDF"
      },
      "outputs": [],
      "source": [
        "customer_data_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customer_data_df['Substation'].unique()"
      ],
      "metadata": {
        "id": "18p7TOorQZco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing\n",
        "- PV Data\n",
        "    - เลือกข้อมูลที่ต้องการ\n",
        "    - พิจารณาความจำเป็นในการ normalize data\n",
        "- Weather data\n",
        "- ปรับข้อมูลให้เป็นคู่ข้อมูลเข้า-ออก"
      ],
      "metadata": {
        "id": "6wSSMd5SXK_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PV Data"
      ],
      "metadata": {
        "id": "yofsGNvCXo0q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### เลือกข้อมูลที่ต้องการ"
      ],
      "metadata": {
        "id": "W3dEVj9IixS_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZ-Udgos0KB7"
      },
      "outputs": [],
      "source": [
        "data_df = customer_data_df[['Substation', 'd_y', 'd_m', 'd_d', 'd_w', 't_h', 't_m', 'P_GEN', 'P_IMPORT']]\n",
        "data_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### พิจารณาความจำเป็นในการ normalize ข้อมูล"
      ],
      "metadata": {
        "id": "YsXTvwXxXs38"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ทดลอง plot ข้อมูล `P_GEN` ของวันที่ 1 กรกฎาคม 2014 แยกแต่ละ substation"
      ],
      "metadata": {
        "id": "42PjqlLiXxDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Filter data for August 1, 2014\n",
        "jul1_2014_data = data_df[(data_df['d_y'] == 2014) & (data_df['d_m'] == 7) & (data_df['d_d'] == 1)]\n",
        "\n",
        "# Aggregate data to hourly level\n",
        "hourly_data = jul1_2014_data.groupby(['Substation', 't_h'])['P_GEN'].sum().reset_index()\n",
        "\n",
        "# Plot P_GEN for each substation\n",
        "plt.figure(figsize=(12, 6))\n",
        "for substation in hourly_data['Substation'].unique():\n",
        "  substation_data = hourly_data[hourly_data['Substation'] == substation]\n",
        "  plt.plot(substation_data['t_h'], substation_data['P_GEN'], label=substation)\n",
        "\n",
        "plt.xlabel('Hour')\n",
        "plt.ylabel('P_GEN (kW)')\n",
        "plt.title('Hourly P_GEN on July 1, 2014 by Substation')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "f6BR793FaOKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ทดลอง plot ข้อมูลเฉลี่ยรายชั่วโมงของทั้ง dataset แยกตาม substation"
      ],
      "metadata": {
        "id": "x6l2KCDxicMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group data by substation and hour, and calculate the average P_GEN for each hour\n",
        "hourly_avg_pgen = data_df.groupby(['Substation', 'd_y', 'd_m', 'd_d', 't_h'])['P_GEN'].sum().reset_index().groupby(['Substation', 't_h'])['P_GEN'].mean().reset_index()\n",
        "\n",
        "# Plot the average hourly P_GEN for each substation\n",
        "plt.figure(figsize=(15, 8))\n",
        "for substation in hourly_avg_pgen['Substation'].unique():\n",
        "  substation_data = hourly_avg_pgen[hourly_avg_pgen['Substation'] == substation]\n",
        "  plt.plot(substation_data['t_h'], substation_data['P_GEN'], label=substation)\n",
        "\n",
        "plt.xlabel('Hour')\n",
        "plt.ylabel('Average P_GEN (kW)')\n",
        "plt.title('Average Hourly P_GEN by Substation')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a9qmZDVkhgke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "จากกราฟ จะเห็นว่าปริมาณไฟฟ้าที่ผลิตได้ของแต่ละ substation ไม่เท่ากัน ไม่น่าจะใช้ข้อมูลใน substation หนึ่งไปทำนายปริมาณการผลิตในอีก substation หนึ่งได้โดยตรง จึงไม่น่าจะเอาข้อมูลทุก substation มารวมกันได้ และน่าจะต้องเลือกทำนายเป็น substation ไป"
      ],
      "metadata": {
        "id": "OM21Z_jnbDdC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ทำข้อมูลรายชั่วโมง"
      ],
      "metadata": {
        "id": "mfb0kL4X9dy0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "sum ข้อมูลในชั่วโมงเดียวกันเข้าด้วยกัน"
      ],
      "metadata": {
        "id": "uuraaQN48LU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Aggregate data_df into hourly data\n",
        "\n",
        "# Aggregate data to hourly level\n",
        "hourly_data_df = data_df.groupby(['Substation', 'd_y', 'd_m', 'd_d', 't_h'])[['P_GEN', 'P_IMPORT']].sum().reset_index()\n",
        "\n",
        "hourly_data_df.head()"
      ],
      "metadata": {
        "id": "8Hy_JWCN8niC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weather data"
      ],
      "metadata": {
        "id": "tS7k69PUjCEZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpUkoAkMMNaU"
      },
      "outputs": [],
      "source": [
        "# Read weather data\n",
        "weather_df = pd.read_excel('/content/Weather Data 2014-11-30.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yH0ZS1dvM5Of"
      },
      "outputs": [],
      "source": [
        "weather_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(weather_df.iloc[0])"
      ],
      "metadata": {
        "id": "7B7ntlEhjeO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weather_df['Site'].unique()"
      ],
      "metadata": {
        "id": "e5ILcc5ykrGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df['Substation'].unique()"
      ],
      "metadata": {
        "id": "enEtt0aGlAMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "จะเห็นว่า มีเฉพาะ\n",
        "- YMCA\n",
        "- Maple Drive East\n",
        "- Forest Road\n",
        "\n",
        "3 site/substation นี้เท่านั้น ที่มีข้อมูลสภาพอากาศ"
      ],
      "metadata": {
        "id": "jRFB9ioGlHrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find intersection of Site and Substation\n",
        "site_selection = set(weather_df['Site'].unique()).intersection(set(data_df['Substation'].unique()))\n",
        "print(site_selection)"
      ],
      "metadata": {
        "id": "oewHVX7bwHCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fields ที่จะใช้\n",
        "- `Site` ชื่อสถานที่ติดตั้งแผง\n",
        "- `Date` วันที่ เดือน ปี (ไม่รวมเวลา)\n",
        "- `Time` เวลา (ชั่วโมง นาที)\n",
        "- `TempOut` อุณหภูมิภายนอกอาคาร\n",
        "- `OutHum` ความชื้นภายนอกอาคาร\n",
        "- `DewPt` อุณหภูมิจุดน้ำค้าง\n",
        "- `WindSpeed` ความเร็วลม\n",
        "- `WindDir` ทิศทางลม\n",
        "- `WindRun` ปริมาณลม\n",
        "- `WindChill` ความเย็นจากลม\n",
        "- `Bar` ความกดอากาศ\n",
        "- `Rain` ปริมาณน้ำฝน\n",
        "- `SolarRad` ความเข้มแสงอาทิตย์"
      ],
      "metadata": {
        "id": "2LP3CTPBjiW6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7Se3BOlM9Rc"
      },
      "outputs": [],
      "source": [
        "weather_df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### เลือกข้อมูลที่ต้องการ"
      ],
      "metadata": {
        "id": "aGRsKRhQopc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['Site', 'Date', 'Time', 'TempOut', 'OutHum', 'DewPt', 'WindSpeed', 'WindDir', 'WindRun', 'WindChill', 'Bar', 'Rain', 'SolarRad']\n",
        "weather_data_df = weather_df[features]\n",
        "weather_data_df.head()"
      ],
      "metadata": {
        "id": "7srJFKbvoq_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "เลือกเฉพาะ Site ที่มีข้อมูลสภาพอากาศ"
      ],
      "metadata": {
        "id": "Jv485EMDv-ab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose only site in site_selection\n",
        "weather_data_df = weather_data_df[weather_data_df['Site'].isin(site_selection)]\n",
        "weather_data_df.head()"
      ],
      "metadata": {
        "id": "UipUSXYqwVhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ตรวจสอบ missing values"
      ],
      "metadata": {
        "id": "ZwGwJUtWo60u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Count missing values for each site\n",
        "\n",
        "# Count missing values for each site in the weather data\n",
        "weather_data_df.groupby('Site').apply(lambda x: x.isnull().sum())"
      ],
      "metadata": {
        "id": "sONRJvnlxG4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ที่จริงแล้ว missing values ถูกแทนด้วย `---` ในข้อมูล"
      ],
      "metadata": {
        "id": "OyCYv5OqscEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count '---' in weahter data by site\n",
        "weather_data_df.groupby('Site').apply(lambda x: x.isin(['---']).sum())"
      ],
      "metadata": {
        "id": "iguEfih-sgxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count data entries for each site\n",
        "weather_data_df.groupby('Site').size()"
      ],
      "metadata": {
        "id": "r_uOWk49x_rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "เติม missing value ด้วยข้อมูลก่อนหน้า (forward fill)"
      ],
      "metadata": {
        "id": "9QHmhUhCsvan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward fill missing values\n",
        "weather_data_df = weather_data_df.replace('---', pd.NA)\n",
        "weather_data_df = weather_data_df.fillna(method='ffill')"
      ],
      "metadata": {
        "id": "sCSfqxY8szvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "นับ Missing values อีกที"
      ],
      "metadata": {
        "id": "5X98oKrStBJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count '---' in weahter data by site\n",
        "weather_data_df.groupby('Site').apply(lambda x: x.isin(['---']).sum())"
      ],
      "metadata": {
        "id": "vY5PDwOis_Cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### แปลงข้อมูลวันที่ เวลา"
      ],
      "metadata": {
        "id": "e6Vvl0v6tMnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Merge Date and Time from weather_data_df into Datetime\n",
        "# Split Datetime to 'd_y', 'd_m', 'd_d', 'd_w', 't_h', 't_m'\n",
        "\n",
        "# Merge Date and Time from weather_data_df into Datetime\n",
        "weather_data_df['Datetime'] = pd.to_datetime(weather_data_df['Date'].astype(str) + ' ' + weather_data_df['Time'].astype(str))\n",
        "\n",
        "# Split Datetime to 'd_y', 'd_m', 'd_d', 'd_w', 't_h', 't_m'\n",
        "weather_data_df['d_y'] = weather_data_df['Datetime'].dt.year\n",
        "weather_data_df['d_m'] = weather_data_df['Datetime'].dt.month\n",
        "weather_data_df['d_d'] = weather_data_df['Datetime'].dt.day\n",
        "weather_data_df['d_w'] = weather_data_df['Datetime'].dt.dayofweek\n",
        "weather_data_df['t_h'] = weather_data_df['Datetime'].dt.hour\n",
        "weather_data_df['t_m'] = weather_data_df['Datetime'].dt.minute"
      ],
      "metadata": {
        "id": "kkxHK1OtqjRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weather_data_df.head()"
      ],
      "metadata": {
        "id": "Y4oeWq5lq6ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### พิจารณาความจำเป็นในการ normalize ข้อมูล"
      ],
      "metadata": {
        "id": "iP59N_1lpNQ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ข้อมูลสภาพอากาศแบ่งออกเป็น\n",
        "- Numeric weather feature\n",
        "- Categorical weather feature"
      ],
      "metadata": {
        "id": "Wn_0F3L00PqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_features = ['TempOut', 'OutHum', 'DewPt', 'WindSpeed', 'WindRun', 'WindChill', 'Bar', 'Rain', 'SolarRad']\n",
        "categorical_features = ['Site', 'WindDir']"
      ],
      "metadata": {
        "id": "JAeYEtCI0ThU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Numeric features"
      ],
      "metadata": {
        "id": "5Vr2tBuC6MFH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ทดลอง plot ข้อมูลรายชั่วโมงแต่ละ weather data ของวันที่ 1 กรฎาคม 2024"
      ],
      "metadata": {
        "id": "hPc1PhuupTfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: plot ข้อมูลรายชั่วโมงแต่ละ numeric feature ของ weather data ในวันที่ 1 กรกฎาคม 2024 แยก Site\n",
        "\n",
        "# Filter data for July 1, 2014\n",
        "jul1_2014_weather_data = weather_data_df[(weather_data_df['d_y'] == 2014) & (weather_data_df['d_m'] == 7) & (weather_data_df['d_d'] == 1)]\n",
        "\n",
        "# Group data by site and hour, and calculate the average of numeric features for each hour\n",
        "hourly_weather = jul1_2014_weather_data.groupby(['Site', 't_h'])[numeric_features].sum().reset_index()\n",
        "\n",
        "# Plot the average hourly weather features for each site\n",
        "for feature in numeric_features:\n",
        "  plt.figure(figsize=(15, 8))\n",
        "  for site in hourly_weather['Site'].unique():\n",
        "    site_data = hourly_weather[hourly_weather['Site'] == site]\n",
        "    plt.plot(site_data['t_h'], site_data[feature], label=site)\n",
        "\n",
        "  plt.xlabel('Hour')\n",
        "  plt.ylabel(f'{feature}')\n",
        "  plt.title(f'Hourly {feature} on July 1, 2014 by Site')\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "4hW5-p8Gu8ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ทดลอง plot ข้อมูลเฉลี่ยรายชั่วโมงของข้อมูลสภาพอากาศแต่ละค่า"
      ],
      "metadata": {
        "id": "Vp2EfYrxubN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weather_data_df.groupby(['Site', 'd_y', 'd_m', 'd_d', 't_h'])[numeric_features].sum().reset_index().groupby(['Site', 't_h']).mean()[numeric_features]"
      ],
      "metadata": {
        "id": "oORhjEbm4kLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Plot ข้อมูลเฉลี่ยรายชั่วโมงของ numeric weather data แยกตาม Site\n",
        "\n",
        "# Group data by site and hour, and calculate the average of numeric features for each hour\n",
        "\n",
        "hourly_avg_weather = weather_data_df.groupby(['Site', 'd_y', 'd_m', 'd_d', 't_h'])[numeric_features].sum().reset_index().groupby(['Site', 't_h']).mean()[numeric_features].reset_index()\n",
        "\n",
        "# Plot the average hourly weather features for each site\n",
        "for feature in numeric_features:\n",
        "  plt.figure(figsize=(15, 8))\n",
        "  for site in hourly_avg_weather['Site'].unique():\n",
        "    site_data = hourly_avg_weather[hourly_avg_weather['Site'] == site]\n",
        "    plt.plot(site_data['t_h'], site_data[feature], label=site)\n",
        "\n",
        "  plt.xlabel('Hour')\n",
        "  plt.ylabel(f'Average {feature}')\n",
        "  plt.title(f'Average Hourly {feature} by Site')\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "lQdlh8kG3pEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "จะเห็นได้ว่า ลักษณะข้อมูลแต่ละพื้นที่นั้นต่างกัน มีค่าสูงสุด-ต่ำสุด ที่ไม่เหมือนกัน\n",
        "\n",
        "นอกจากนี้ ข้อมูลสภาพอากาศแต่ละค่า ก็มี scale ที่ต่างกันค่อนข้างมาก\n",
        "\n",
        "หากต้องการใช้ข้อมูลสภาพอากาศทั้งหมดมาใช้ในการทำนาย ต้องมีการ normalize ข้อมูลสภาพอากาศแต่ละค่าให้อยู่ใน scale เดียวกัน"
      ],
      "metadata": {
        "id": "QI-Lg1_t5nhC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Categorical features\n",
        "\n",
        "- `Site` ใช้อ้างอิงเพื่อกรองข้อมูลเพื่อสร้าง model แยก ไม่จำเป็นต้องทำอะไรเพิ่ม\n",
        "- `WindDir` ทิศทางลม\n"
      ],
      "metadata": {
        "id": "NYEUusMx6UUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weather_data_df['WindDir'].unique()"
      ],
      "metadata": {
        "id": "b6Hk7IK66ZAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "เมื่อพิจารณาแล้ว พบว่า ทิศทางลมเป็น category น่าจะใช้ one-hot vector แทนทิศทาง"
      ],
      "metadata": {
        "id": "rXmg4H6Y7F4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert WindDir to OneHotEncoding\n",
        "weather_data_df = pd.get_dummies(weather_data_df, columns=['WindDir'])\n",
        "\n",
        "weather_data_df.head()"
      ],
      "metadata": {
        "id": "n3h5w5Sr-QS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ทำข้อมูลรายชั่วโมง"
      ],
      "metadata": {
        "id": "ii6cV_nB9xah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "สร้าง list ของ boolean feature"
      ],
      "metadata": {
        "id": "0x5JpMa3_r8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Create list of boolean features from WindDir\n",
        "\n",
        "# สร้าง list ของ boolean feature จาก WindDir\n",
        "wind_dir_features = [col for col in weather_data_df.columns if col.startswith('WindDir_')]\n",
        "\n",
        "print(wind_dir_features)"
      ],
      "metadata": {
        "id": "tVK7e1JI_w8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "รวมข้อมูลในชั่วโมงเดียวกันเข้าด้วยกัน"
      ],
      "metadata": {
        "id": "mp7VK6YRHaVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create hourly weather data for numeric features and boolean features\n",
        "hourly_weather_df = weather_data_df.groupby(['Site', 'd_y', 'd_m', 'd_d', 't_h'])[numeric_features + wind_dir_features].sum().reset_index()\n",
        "\n",
        "hourly_weather_df.head()"
      ],
      "metadata": {
        "id": "ozBLjfVN97eT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hourly_weather_df.columns"
      ],
      "metadata": {
        "id": "RLEwUzDTHrXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create input-output dataset"
      ],
      "metadata": {
        "id": "D6si2N_C5g68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Merge hourly_data_df with hourly_weather_df on Substation/Site, d_y, y_m, d_d, t_h\n",
        "# Keep numeric_features and wind_dir_features\n",
        "\n",
        "# Merge hourly_data_df with hourly_weather_df on Substation/Site, d_y, y_m, d_d, t_h\n",
        "merged_df = pd.merge(hourly_data_df, hourly_weather_df, left_on=['Substation', 'd_y', 'd_m', 'd_d', 't_h'],\n",
        "                     right_on=['Site', 'd_y', 'd_m', 'd_d', 't_h'], how='inner')\n",
        "\n",
        "# Keep only numeric_features and wind_dir_features\n",
        "selected_features = ['Site', 'd_y', 'd_m', 'd_d', 't_h'] + numeric_features + wind_dir_features + ['P_GEN', 'P_IMPORT']\n",
        "merged_df = merged_df[selected_features]\n",
        "\n",
        "merged_df.head()"
      ],
      "metadata": {
        "id": "w_-twnUv7SbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.info()"
      ],
      "metadata": {
        "id": "dlGPqVUpB9Wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample Site - YMCA"
      ],
      "metadata": {
        "id": "UEpY3fKhFIFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose data from YMCA Site\n",
        "ymca_df = merged_df[merged_df['Site'] == 'YMCA']"
      ],
      "metadata": {
        "id": "9NI04xkyFLwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Create datetime column from d_y, d_m, d_d, d_h\n",
        "\n",
        "# Create datetime column from d_y, d_m, d_d, d_h\n",
        "ymca_df['Datetime'] = pd.to_datetime(ymca_df[['d_y', 'd_m', 'd_d', 't_h']].astype(str).agg('-'.join, axis=1), format='%Y-%m-%d-%H')"
      ],
      "metadata": {
        "id": "xs_8P63kFiMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ymca_df.head()"
      ],
      "metadata": {
        "id": "OhjAAtl1JykM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop Site, d_y from ymca_df\n",
        "ymca_df = ymca_df.drop(['Site', 'd_y'], axis=1)"
      ],
      "metadata": {
        "id": "M8UiMNVcLKCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ymca_df.columns"
      ],
      "metadata": {
        "id": "TDuE5BmTOaU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Set P_GEN and P_IMPORT to output\n",
        "# The rest of columns are inputs\n",
        "# Create time series input-output pair, using 3-hr history input data to predict outputs\n",
        "\n",
        "# Assuming your dataframe is named 'ymca_df' and has 'P_GEN', 'P_IMPORT', and other columns as inputs.\n",
        "import numpy as np\n",
        "\n",
        "def create_timeseries_dataset(df, history_length=3):\n",
        "  \"\"\"\n",
        "  Creates a time series input-output dataset using historical data.\n",
        "\n",
        "  Args:\n",
        "    df: Pandas DataFrame containing the data.\n",
        "    history_length: Number of hours of historical data to use as input.\n",
        "\n",
        "  Returns:\n",
        "    A tuple of (inputs, outputs), where inputs is a numpy array of input data\n",
        "    and outputs is a numpy array of corresponding output data.\n",
        "  \"\"\"\n",
        "\n",
        "  inputs = []\n",
        "  outputs = []\n",
        "\n",
        "  for i in range(history_length, len(df)):\n",
        "    input_data = df.iloc[i - history_length:i].values\n",
        "    output_data = df[['P_GEN', 'P_IMPORT']].iloc[i].values\n",
        "    inputs.append(input_data)\n",
        "    outputs.append(output_data)\n",
        "\n",
        "  return np.array(inputs), np.array(outputs)\n",
        "\n",
        "# Sort ymca_df by datetime\n",
        "ymca_df = ymca_df.sort_values('Datetime').drop('Datetime', axis=1)\n",
        "inputs, outputs = create_timeseries_dataset(ymca_df)\n",
        "\n",
        "print(inputs.shape)  # Shape of input data: (num_samples, history_length, num_features)\n",
        "print(outputs.shape) # Shape of output data: (num_samples, 2)"
      ],
      "metadata": {
        "id": "pBNCHnOoLTQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs[0]"
      ],
      "metadata": {
        "id": "5InlQWuPOO2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs[0]"
      ],
      "metadata": {
        "id": "TmwvUfaWLK80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Pipelines"
      ],
      "metadata": {
        "id": "RqMgSrR9PQea"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple linear regression"
      ],
      "metadata": {
        "id": "eCniK_QjI61B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Setup sklearn pipeline\n",
        "# - Normalize input values using MinMaxScaler\n",
        "# - Create timeseries 5-fold cross validation\n",
        "# - Train a regression model\n",
        "# - Report error on each fold\n",
        "# - Evaluate P_GEN and P_IMPORT prediction using RMSE\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'inputs' and 'outputs' are your prepared time series data\n",
        "\n",
        "# Create a pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', MinMaxScaler()),  # Normalize input data\n",
        "    ('model', LinearRegression())  # Train a linear regression model\n",
        "])\n",
        "\n",
        "# Define the cross-validation strategy (TimeSeriesSplit)\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "# Loop through the cross-validation folds\n",
        "for train_index, test_index in tscv.split(inputs):\n",
        "    X_train, X_test = inputs[train_index], inputs[test_index]\n",
        "    y_train, y_test = outputs[train_index], outputs[test_index]\n",
        "\n",
        "    # Fit the pipeline on the training data\n",
        "    pipeline.fit(X_train.reshape(X_train.shape[0], -1), y_train)\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_pred = pipeline.predict(X_test.reshape(X_test.shape[0], -1))\n",
        "\n",
        "    # Calculate and report RMSE for P_GEN and P_IMPORT\n",
        "    rmse_pgen = np.sqrt(mean_squared_error(y_test[:, 0], y_pred[:, 0]))\n",
        "    rmse_pimport = np.sqrt(mean_squared_error(y_test[:, 1], y_pred[:, 1]))\n",
        "\n",
        "    print(f\"Fold RMSE - P_GEN: {rmse_pgen:.4f}, P_IMPORT: {rmse_pimport:.4f}\")\n"
      ],
      "metadata": {
        "id": "23pvX9IkIdeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## เปรียบเทียบ LinearRegression, Ridge และ Lasso"
      ],
      "metadata": {
        "id": "o4gs0g6RQcof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Compare LinearRegression, Ridge, Lasso model using the same pipieline\n",
        "\n",
        "# Define models to compare\n",
        "models = [\n",
        "    (\"LinearRegression\", LinearRegression()),\n",
        "    (\"Ridge\", Ridge()),\n",
        "    (\"Lasso\", Lasso()),\n",
        "]\n",
        "\n",
        "for model_name, model in models:\n",
        "  print(f\"\\nEvaluating {model_name}:\")\n",
        "\n",
        "  # Create a pipeline with the current model\n",
        "  pipeline = Pipeline([\n",
        "      ('scaler', MinMaxScaler()),\n",
        "      ('model', model)\n",
        "  ])\n",
        "\n",
        "  # RMSE\n",
        "  rmse_pgen_list = []\n",
        "  rmse_pimport_list = []\n",
        "\n",
        "  # Loop through the cross-validation folds\n",
        "  for train_index, test_index in tscv.split(inputs):\n",
        "      X_train, X_test = inputs[train_index], inputs[test_index]\n",
        "      y_train, y_test = outputs[train_index], outputs[test_index]\n",
        "\n",
        "      # Fit the pipeline on the training data\n",
        "      pipeline.fit(X_train.reshape(X_train.shape[0], -1), y_train)\n",
        "\n",
        "      # Predict on the test data\n",
        "      y_pred = pipeline.predict(X_test.reshape(X_test.shape[0], -1))\n",
        "\n",
        "      # Calculate and report RMSE for P_GEN and P_IMPORT\n",
        "      rmse_pgen = np.sqrt(mean_squared_error(y_test[:, 0], y_pred[:, 0]))\n",
        "      rmse_pimport = np.sqrt(mean_squared_error(y_test[:, 1], y_pred[:, 1]))\n",
        "\n",
        "      print(f\"Fold RMSE - P_GEN: {rmse_pgen:.4f}, P_IMPORT: {rmse_pimport:.4f}\")\n",
        "\n",
        "      rmse_pgen_list.append(rmse_pgen)\n",
        "      rmse_pimport_list.append(rmse_pimport)\n",
        "\n",
        "  # Find average RMSE\n",
        "  avg_rmse_pgen = np.mean(rmse_pgen_list)\n",
        "  avg_rmse_pimport = np.mean(rmse_pimport_list)\n",
        "\n",
        "  print(f\"\\nAverage RMSE - P_GEN: {avg_rmse_pgen:.4f}, P_IMPORT: {avg_rmse_pimport:.4f}\")"
      ],
      "metadata": {
        "id": "Ooqbzoq-QOwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# แบบฝึกหัด\n",
        "\n",
        "1. เปลี่ยน Site เป็น Forest Road\n",
        "2. เปลี่ยน Site เป็น Maple Drive East\n",
        "\n",
        "โมเดลใดแม่นที่สุดเมื่อใช้กับทั้งสาม site (YMCA, Forest Road, Maple East)"
      ],
      "metadata": {
        "id": "TER4GJNKRdjO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Forest Road site"
      ],
      "metadata": {
        "id": "Q1hsAeirRyUX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5I__hWAGRbNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Maple Drive East"
      ],
      "metadata": {
        "id": "rdp_PzyNSJrv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tx7TF8SnSN1q"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}